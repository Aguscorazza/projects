{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23bed9a2",
   "metadata": {},
   "source": [
    "## Fetch the data\n",
    "\n",
    "The data files are located in the **data** folder. The training set contains [pos/, neg/] directories for the reviews with binary labels positive and negative. Within these directories, reviews are stored in text files named following the convention [[id]_[rating].txt] where [id] is a unique id and [rating] is the star rating for that review on a 1-10 scale. For example, the file [train/pos/200_8.txt] is the text for a positive-labeled train set example with unique id 200 and star rating 8/10 from IMDb.\n",
    "\n",
    "Let's write some functions to get and store the dato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd875890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_imbd_dataset(data_path, unsup = False):\n",
    "    \"\"\"\n",
    "    Load the IMDb dataset into Pandas DataFrames.\n",
    "\n",
    "    Parameters:\n",
    "        data_path (str): The root directory where the IMDb dataset is stored.\n",
    "        unsup (bool): Whether the data is labeled or not\n",
    "        \n",
    "    Returns:\n",
    "        df (pandas.DataFrame): A DataFrame containing the reviews and their labels.\n",
    "    \"\"\"\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    if not unsup:\n",
    "        for label in ['pos', 'neg']:\n",
    "            label_dir = os.path.join(data_path, label)\n",
    "            for filename in os.listdir(label_dir):\n",
    "                filepath = os.path.join(label_dir, filename)\n",
    "                with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                    review_text = file.read()\n",
    "                rating = int(filename.split('_')[1].split('.')[0])\n",
    "                sentiment = 1 if label == 'pos' else 0\n",
    "                reviews.append(review_text)\n",
    "                labels.append(sentiment)\n",
    "        df = pd.DataFrame({'review': reviews, 'sentiment': labels})\n",
    "        return df\n",
    "    else:\n",
    "        label_dir = os.path.join(data_path, 'unsup')\n",
    "        for filename in os.listdir(label_dir):\n",
    "                filepath = os.path.join(label_dir, filename)\n",
    "                with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                    review_text = file.read()\n",
    "                reviews.append(review_text)\n",
    "        df = pd.DataFrame({'review': reviews})\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96c7d451",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = load_imbd_dataset('data/train')\n",
    "test_set = load_imbd_dataset('data/test')\n",
    "unlabeled_train_set = load_imbd_dataset('data/train', unsup=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64270449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9bb2934c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['review', 'sentiment'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9549942",
   "metadata": {},
   "source": [
    "The train set has 25000 rows and 3 columns ('id', 'sentiment' and 'review'). Now let's take a look at a few reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8f9fd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they'll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it's like to be homeless? That is Goddard Bolt's lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet's on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can't step off the sidewalk. He's given the nickname Pepto by a vagrant after it's written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They're survivors. Bolt isn't. He's not used to reaching mutual agreements like he once did when being rich where it's fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn't necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it's like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don't know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.\n"
     ]
    }
   ],
   "source": [
    "print(train_set[\"review\"][1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87e9ed6",
   "metadata": {},
   "source": [
    "We can see some HTML tags such as `<br/>`, abbreviations and punctuation. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f945eb93",
   "metadata": {},
   "source": [
    "## Data Cleaning and Text Preprocessing\n",
    "We will implement all the preprocessing steps as Transformers, so then we can apply them in a preprocessing Pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67beaf5",
   "metadata": {},
   "source": [
    "### Removing HTML Markup\n",
    "First, we'll remove the HTML tags. We will use the **Beautiful Soup** package. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5b0fc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class HTMLTagRemover(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Function to remove HTML tags from each element in the input X\n",
    "        def remove_html_tags(html_text):\n",
    "            soup = BeautifulSoup(html_text, 'html.parser')\n",
    "            return soup.get_text()\n",
    "        \n",
    "        return [remove_html_tags(text) for text in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066139df",
   "metadata": {},
   "source": [
    "Let's try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65a5c368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.<br /><br />But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.<br /><br />Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.<br /><br />While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.<br /><br />Or maybe this film will inspire you to help others.']\n"
     ]
    }
   ],
   "source": [
    "example = [train_set[\"review\"][1]]\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6dcaabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Homelessness (or Houselessness as George Carlin stated) has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school, work, or vote for the matter. Most people think of the homeless as just a lost cause while worrying about things such as racism, the war on Iraq, pressuring kids to succeed, technology, the elections, inflation, or worrying if they\\'ll be next to end up on the streets.But what if you were given a bet to live on the streets for a month without the luxuries you once had from a home, the entertainment sets, a bathroom, pictures on the wall, a computer, and everything you once treasure to see what it\\'s like to be homeless? That is Goddard Bolt\\'s lesson.Mel Brooks (who directs) who stars as Bolt plays a rich man who has everything in the world until deciding to make a bet with a sissy rival (Jeffery Tambor) to see if he can live in the streets for thirty days without the luxuries; if Bolt succeeds, he can do what he wants with a future project of making more buildings. The bet\\'s on where Bolt is thrown on the street with a bracelet on his leg to monitor his every move where he can\\'t step off the sidewalk. He\\'s given the nickname Pepto by a vagrant after it\\'s written on his forehead where Bolt meets other characters including a woman by the name of Molly (Lesley Ann Warren) an ex-dancer who got divorce before losing her home, and her pals Sailor (Howard Morris) and Fumes (Teddy Wilson) who are already used to the streets. They\\'re survivors. Bolt isn\\'t. He\\'s not used to reaching mutual agreements like he once did when being rich where it\\'s fight or flight, kill or be killed.While the love connection between Molly and Bolt wasn\\'t necessary to plot, I found \"Life Stinks\" to be one of Mel Brooks\\' observant films where prior to being a comedy, it shows a tender side compared to his slapstick work such as Blazing Saddles, Young Frankenstein, or Spaceballs for the matter, to show what it\\'s like having something valuable before losing it the next day or on the other hand making a stupid bet like all rich people do when they don\\'t know what to do with their money. Maybe they should give it to the homeless instead of using it like Monopoly money.Or maybe this film will inspire you to help others.']\n"
     ]
    }
   ],
   "source": [
    "html_remover = HTMLTagRemover()\n",
    "example = html_remover.transform(example)\n",
    "print(example)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3771bd6a",
   "metadata": {},
   "source": [
    "### Dealing with Punctuation, Numbers and Stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f6a58",
   "metadata": {},
   "source": [
    "When considering text cleaning, it is essential to tailor the approach to the specific data problem we aim to solve. For certain tasks, removing punctuation can be beneficial, but in the context of sentiment analysis, expressions like \"!!!\" or \":-(\" might contain sentiment and could be treated as words. Nevertheless, for simplicity, we will proceed with punctuation removal.\n",
    "\n",
    "Similarly, we'll exclude numbers, although alternative methods exist, such as treating them as words or substituting them with a placeholder like \"NUM.\"\n",
    "\n",
    "To execute the punctuation and number removal, we'll leverage the re package, which handles regular expressions. Additionally, we'll tokenize the reviews, breaking them down into individual words.\n",
    "\n",
    "Moreover, we'll apply lemmatization, a process that converts words to their base forms. This ensures proper morphological meaning by referencing a dictionary within the library.\n",
    "\n",
    "Lastly, we must address frequently occurring words that carry little meaning, known as \"stop words\". In English, these encompass words like \"a,\" \"and,\" \"is,\" and \"the.\" Fortunately, Python packages like the Natural Language Toolkit (NLTK) provide built-in stop word lists that we can utilize by importing them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e61a94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "class TextCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, remove_stopwords = False, lemmatization=True):\n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('punkt')\n",
    "        \n",
    "        self.remove_stopwords = remove_stopwords\n",
    "        self.lemmatization = lemmatization\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        # Function to clean text (lowercase, remove numbers and punctuation)\n",
    "        def clean_text(text):\n",
    "            text = text.lower()\n",
    "            \n",
    "            # Remove numbers using regex\n",
    "            text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "            #Remove URLs\n",
    "            text = re.sub(r'(https|http)?:\\/\\/(\\w|\\.|\\/|\\?|\\=|\\&|\\%)*\\b', '', text, flags=re.MULTILINE)\n",
    "\n",
    "            # Remove punctuation using string library\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "            \n",
    "            \n",
    "            # Split the text into words\n",
    "            words = text.split()\n",
    "            \n",
    "            # Remove stop words from \"words\"\n",
    "            if self.remove_stopwords:\n",
    "                stops = set(stopwords.words(\"english\"))   \n",
    "                words = [w for w in words if not w in stops]\n",
    "            \n",
    "            if self.lemmatization:\n",
    "                lemmatizer = WordNetLemmatizer()\n",
    "                words = [lemmatizer.lemmatize(word, 'v') for word in words]\n",
    "\n",
    "            return (\" \".join(words)) \n",
    "\n",
    "        return [clean_text(text) for text in X]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e75a00",
   "metadata": {},
   "source": [
    "Let's try this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c46caf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Agustin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Agustin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['homelessness or houselessness as george carlin state have be an issue for years but never a plan to help those on the street that be once consider human who do everything from go to school work or vote for the matter most people think of the homeless as just a lose cause while worry about things such as racism the war on iraq pressure kid to succeed technology the elections inflation or worry if theyll be next to end up on the streetsbut what if you be give a bet to live on the streets for a month without the luxuries you once have from a home the entertainment set a bathroom picture on the wall a computer and everything you once treasure to see what its like to be homeless that be goddard bolt lessonmel brook who direct who star as bolt play a rich man who have everything in the world until decide to make a bet with a sissy rival jeffery tambor to see if he can live in the streets for thirty days without the luxuries if bolt succeed he can do what he want with a future project of make more build the bet on where bolt be throw on the street with a bracelet on his leg to monitor his every move where he cant step off the sidewalk hes give the nickname pepto by a vagrant after its write on his forehead where bolt meet other character include a woman by the name of molly lesley ann warren an exdancer who get divorce before lose her home and her pal sailor howard morris and fume teddy wilson who be already use to the streets theyre survivors bolt isnt hes not use to reach mutual agreements like he once do when be rich where its fight or flight kill or be killedwhile the love connection between molly and bolt wasnt necessary to plot i find life stink to be one of mel brook observant film where prior to be a comedy it show a tender side compare to his slapstick work such as blaze saddle young frankenstein or spaceballs for the matter to show what its like have something valuable before lose it the next day or on the other hand make a stupid bet like all rich people do when they dont know what to do with their money maybe they should give it to the homeless instead of use it like monopoly moneyor maybe this film will inspire you to help others']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaner = TextCleaner()\n",
    "example = text_cleaner.transform(example)\n",
    "example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896effc0",
   "metadata": {},
   "source": [
    "### Building the Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93c2c1c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Agustin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Agustin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "preprocessing_pipeline = Pipeline([\n",
    "    ('html_tag_remover', HTMLTagRemover()),\n",
    "    ('text_cleaner', TextCleaner(remove_stopwords=True, lemmatization=True)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8702d26",
   "metadata": {},
   "source": [
    "Now we can use this pipeline to transform our training set. Let's prepare our training set and preprocess it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae7162fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agustin\\AppData\\Local\\Temp\\ipykernel_10604\\1586490070.py:11: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_text, 'html.parser')\n"
     ]
    }
   ],
   "source": [
    "# Shuffle our training and test sets:\n",
    "train_set = train_set.sample(frac=1, random_state=42)\n",
    "test_set = test_set.sample(frac=1, random_state=42)\n",
    "\n",
    "train_set = train_set.reset_index(drop=True)\n",
    "test_set = test_set.reset_index(drop=True)\n",
    "\n",
    "X_train_full, y_train_full = train_set[\"review\"], train_set[\"sentiment\"]\n",
    "\n",
    "# Transform our training set\n",
    "X_train_transformed_full = preprocessing_pipeline.fit_transform(X_train_full)\n",
    "\n",
    "# Split the train set into a validation set.\n",
    "X_train_transformed, X_valid_transformed = X_train_transformed_full[:20000], X_train_transformed_full[20000:]\n",
    "y_train, y_valid = y_train_full[:20000], y_train_full[20000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e2143c",
   "metadata": {},
   "source": [
    "## Numerical Representations for our Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9fce54",
   "metadata": {},
   "source": [
    "Now that we have our training reviews tidied up, we need to convert them to some kind of numeric representation for machine learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0575c5b1",
   "metadata": {},
   "source": [
    "### Bag of Words\n",
    "One common approach is called a **Bag of Words**. The Bag of Words model learns a vocabulary from all of the documents, then models each document by counting the number of times each word appears.\n",
    "\n",
    "In the IMDB data, we have a very large number of reviews, which will give us a large vocabulary. To limit the size of the feature vectors, we should choose some maximum vocabulary size. Below, we use the **10000 most frequent words and bigrams** (remembering that stop words have already been removed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec02b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_vectorizer = CountVectorizer(analyzer='word', ngram_range=(1,2), tokenizer=None, preprocessor=None, stop_words=None, max_features=10000)\n",
    "\n",
    "X_train_vectorized_bow = bow_vectorizer.fit_transform(X_train_transformed).toarray()\n",
    "X_valid_vectorized_bow = bow_vectorizer.transform(X_valid_transformed).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11001d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 10000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89babab",
   "metadata": {},
   "source": [
    "Now our training data has 20,000 rows and 10,000 features (one for each vocabulary word/bigram)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10a4c9ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abandon' 'abc' 'abilities' ... 'zoom' 'zorro' 'zu']\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the words in the vocabulary\n",
    "vocab = bow_vectorizer.get_feature_names_out()\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c19e5",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69f8f9cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(min_df=5, max_df=0.8, sublinear_tf=True, use_idf=True, stop_words=None)\n",
    "\n",
    "X_train_vectorized_tfidf = tfidf_vectorizer.fit_transform(X_train_transformed).toarray()\n",
    "X_valid_vectorized_tfidf = tfidf_vectorizer.transform(X_valid_transformed).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6283df23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 20995)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e9b7851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vectorized_tfidf[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9109d9ae",
   "metadata": {},
   "source": [
    "## Building our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46211aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c236ac",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39de30c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW Metrics:\n",
      "[0.839   0.84825 0.847   0.83525 0.8435 ]\n",
      "0.8426\n",
      "TF-IDF Metrics:\n",
      "[0.8435  0.8445  0.84275 0.83575 0.8385 ]\n",
      "0.841\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "rf_clf = RandomForestClassifier(n_estimators = 100)\n",
    "\n",
    "print(\"BOW Metrics:\")\n",
    "cv = cross_val_score(rf_clf, X_train_vectorized_bow, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())\n",
    "\n",
    "print(\"TF-IDF Metrics:\")\n",
    "cv = cross_val_score(rf_clf, X_train_vectorized_tfidf, y_train, cv=5)\n",
    "print(cv)\n",
    "print(cv.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9f7c24",
   "metadata": {},
   "source": [
    "### FeedForward Neural Network (FNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7ece9953",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agustin\\AppData\\Local\\Temp\\ipykernel_10604\\4030120357.py:18: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_clf_bow = KerasClassifier(build_model, input_shape=X_train_vectorized_bow.shape[1:])\n",
      "C:\\Users\\Agustin\\AppData\\Local\\Temp\\ipykernel_10604\\4030120357.py:19: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  keras_clf_tfidf = KerasClassifier(build_model, input_shape=X_train_vectorized_tfidf.shape[1:])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from scipy.stats import reciprocal\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def build_model(input_shape, n_hidden=1, n_neurons=30, learning_rate=3e-3):\n",
    "    model = keras.models.Sequential()\n",
    "    options = {\"input_shape\": input_shape}\n",
    "    for layer in range(n_hidden):\n",
    "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\", **options))\n",
    "        options = {}\n",
    "    model.add(keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "keras_clf_bow = KerasClassifier(build_model, input_shape=X_train_vectorized_bow.shape[1:])\n",
    "keras_clf_tfidf = KerasClassifier(build_model, input_shape=X_train_vectorized_tfidf.shape[1:])\n",
    "\n",
    "param_distribs = {\n",
    " \"n_hidden\": [0, 1, 2, 3],\n",
    " \"n_neurons\": np.arange(1, 100),\n",
    "}\n",
    "\n",
    "bow_rnd_search_cv =  RandomizedSearchCV(keras_clf_bow, param_distribs, n_iter=10, cv=3)\n",
    "tfidf_rnd_search_cv = RandomizedSearchCV(keras_clf_tfidf, param_distribs, n_iter=10, cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec7458ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW:\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 8s 16ms/step - loss: 0.3676 - accuracy: 0.8489 - val_loss: 0.3062 - val_accuracy: 0.8758\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.1542 - accuracy: 0.9411 - val_loss: 0.3555 - val_accuracy: 0.8736\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.0669 - accuracy: 0.9784 - val_loss: 0.4818 - val_accuracy: 0.8686\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 3s 6ms/step - loss: 0.0218 - accuracy: 0.9943 - val_loss: 0.6874 - val_accuracy: 0.8608\n",
      "209/209 [==============================] - 2s 5ms/step - loss: 0.2987 - accuracy: 0.8783\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 5s 10ms/step - loss: 0.3711 - accuracy: 0.8441 - val_loss: 0.3190 - val_accuracy: 0.8702\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 3s 8ms/step - loss: 0.1653 - accuracy: 0.9380 - val_loss: 0.3456 - val_accuracy: 0.8686\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.0822 - accuracy: 0.9717 - val_loss: 0.4558 - val_accuracy: 0.8634\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.0387 - accuracy: 0.9888 - val_loss: 0.5899 - val_accuracy: 0.8582\n",
      "209/209 [==============================] - 2s 4ms/step - loss: 0.3293 - accuracy: 0.8683\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 4s 8ms/step - loss: 0.3727 - accuracy: 0.8429 - val_loss: 0.3039 - val_accuracy: 0.8810\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 10s 24ms/step - loss: 0.1638 - accuracy: 0.9385 - val_loss: 0.3552 - val_accuracy: 0.8678\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.0768 - accuracy: 0.9748 - val_loss: 0.4917 - val_accuracy: 0.8658\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0312 - accuracy: 0.9908 - val_loss: 0.6096 - val_accuracy: 0.8572\n",
      "209/209 [==============================] - 3s 5ms/step - loss: 0.3110 - accuracy: 0.8763\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 3s 6ms/step - loss: 0.4892 - accuracy: 0.8252 - val_loss: 0.3908 - val_accuracy: 0.8702\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3281 - accuracy: 0.9003 - val_loss: 0.3356 - val_accuracy: 0.8806\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2692 - accuracy: 0.9187 - val_loss: 0.3138 - val_accuracy: 0.8838\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.2331 - accuracy: 0.9313 - val_loss: 0.3005 - val_accuracy: 0.8856\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2066 - accuracy: 0.9402 - val_loss: 0.2946 - val_accuracy: 0.8876\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1857 - accuracy: 0.9494 - val_loss: 0.2916 - val_accuracy: 0.8844\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1689 - accuracy: 0.9563 - val_loss: 0.2925 - val_accuracy: 0.8832\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1545 - accuracy: 0.9608 - val_loss: 0.2915 - val_accuracy: 0.8860\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1424 - accuracy: 0.9657 - val_loss: 0.2936 - val_accuracy: 0.8824\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1316 - accuracy: 0.9704 - val_loss: 0.2964 - val_accuracy: 0.8824\n",
      "Epoch 11/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1219 - accuracy: 0.9732 - val_loss: 0.3000 - val_accuracy: 0.8796\n",
      "209/209 [==============================] - 2s 5ms/step - loss: 0.2870 - accuracy: 0.8855\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 6s 8ms/step - loss: 0.4835 - accuracy: 0.8237 - val_loss: 0.3914 - val_accuracy: 0.8716\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3237 - accuracy: 0.9011 - val_loss: 0.3358 - val_accuracy: 0.8802\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2646 - accuracy: 0.9191 - val_loss: 0.3127 - val_accuracy: 0.8852\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2282 - accuracy: 0.9338 - val_loss: 0.3026 - val_accuracy: 0.8840\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2018 - accuracy: 0.9436 - val_loss: 0.2942 - val_accuracy: 0.8876\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1812 - accuracy: 0.9505 - val_loss: 0.2915 - val_accuracy: 0.8858\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1646 - accuracy: 0.9565 - val_loss: 0.2900 - val_accuracy: 0.8866\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1504 - accuracy: 0.9623 - val_loss: 0.2912 - val_accuracy: 0.8854\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1384 - accuracy: 0.9662 - val_loss: 0.2925 - val_accuracy: 0.8842\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1278 - accuracy: 0.9713 - val_loss: 0.2950 - val_accuracy: 0.8854\n",
      "209/209 [==============================] - 2s 5ms/step - loss: 0.3004 - accuracy: 0.8825\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 4s 5ms/step - loss: 0.4823 - accuracy: 0.8291 - val_loss: 0.3893 - val_accuracy: 0.8684\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3246 - accuracy: 0.9003 - val_loss: 0.3355 - val_accuracy: 0.8806\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2665 - accuracy: 0.9177 - val_loss: 0.3127 - val_accuracy: 0.8836\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2309 - accuracy: 0.9303 - val_loss: 0.3030 - val_accuracy: 0.8838\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2050 - accuracy: 0.9398 - val_loss: 0.2959 - val_accuracy: 0.8838\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1848 - accuracy: 0.9488 - val_loss: 0.2955 - val_accuracy: 0.8832\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1682 - accuracy: 0.9543 - val_loss: 0.2923 - val_accuracy: 0.8856\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.1543 - accuracy: 0.9597 - val_loss: 0.2938 - val_accuracy: 0.8854\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1420 - accuracy: 0.9655 - val_loss: 0.2976 - val_accuracy: 0.8824\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1314 - accuracy: 0.9695 - val_loss: 0.2973 - val_accuracy: 0.8826\n",
      "209/209 [==============================] - 2s 3ms/step - loss: 0.2910 - accuracy: 0.8884\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 21s 46ms/step - loss: 0.3688 - accuracy: 0.8504 - val_loss: 0.3121 - val_accuracy: 0.8766\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 19s 46ms/step - loss: 0.1601 - accuracy: 0.9404 - val_loss: 0.3430 - val_accuracy: 0.8720\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 20s 47ms/step - loss: 0.0852 - accuracy: 0.9732 - val_loss: 0.4321 - val_accuracy: 0.8652\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 20s 48ms/step - loss: 0.0431 - accuracy: 0.9885 - val_loss: 0.5272 - val_accuracy: 0.8644\n",
      "209/209 [==============================] - 11s 34ms/step - loss: 0.3002 - accuracy: 0.8808\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 22s 51ms/step - loss: 0.3633 - accuracy: 0.8528 - val_loss: 0.3194 - val_accuracy: 0.8724\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 27s 65ms/step - loss: 0.1609 - accuracy: 0.9435 - val_loss: 0.3498 - val_accuracy: 0.8720\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 27s 64ms/step - loss: 0.0871 - accuracy: 0.9705 - val_loss: 0.4199 - val_accuracy: 0.8676\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 31s 74ms/step - loss: 0.0481 - accuracy: 0.9865 - val_loss: 0.5021 - val_accuracy: 0.8654\n",
      "209/209 [==============================] - 11s 48ms/step - loss: 0.3331 - accuracy: 0.8664\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 30s 68ms/step - loss: 0.3640 - accuracy: 0.8495 - val_loss: 0.3284 - val_accuracy: 0.8700\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 20s 48ms/step - loss: 0.1591 - accuracy: 0.9422 - val_loss: 0.3577 - val_accuracy: 0.8704\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 20s 49ms/step - loss: 0.0869 - accuracy: 0.9734 - val_loss: 0.4242 - val_accuracy: 0.8690\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 20s 47ms/step - loss: 0.0426 - accuracy: 0.9893 - val_loss: 0.5068 - val_accuracy: 0.8650\n",
      "209/209 [==============================] - 8s 32ms/step - loss: 0.3293 - accuracy: 0.8672\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 22s 49ms/step - loss: 0.3763 - accuracy: 0.8480 - val_loss: 0.3034 - val_accuracy: 0.8772\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 21s 50ms/step - loss: 0.1615 - accuracy: 0.9405 - val_loss: 0.3718 - val_accuracy: 0.8704\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 20s 49ms/step - loss: 0.0690 - accuracy: 0.9773 - val_loss: 0.4998 - val_accuracy: 0.8600\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 19s 45ms/step - loss: 0.0358 - accuracy: 0.9881 - val_loss: 0.5980 - val_accuracy: 0.8678\n",
      "209/209 [==============================] - 8s 34ms/step - loss: 0.2963 - accuracy: 0.8759\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 21s 47ms/step - loss: 0.3767 - accuracy: 0.8429 - val_loss: 0.2989 - val_accuracy: 0.8826\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 19s 46ms/step - loss: 0.1604 - accuracy: 0.9389 - val_loss: 0.3419 - val_accuracy: 0.8728\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 19s 47ms/step - loss: 0.0775 - accuracy: 0.9716 - val_loss: 0.4757 - val_accuracy: 0.8598\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 19s 46ms/step - loss: 0.0469 - accuracy: 0.9838 - val_loss: 0.5808 - val_accuracy: 0.8604\n",
      "209/209 [==============================] - 8s 34ms/step - loss: 0.3135 - accuracy: 0.8713\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 26s 47ms/step - loss: 0.3706 - accuracy: 0.8469 - val_loss: 0.3101 - val_accuracy: 0.8752\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 20s 48ms/step - loss: 0.1617 - accuracy: 0.9390 - val_loss: 0.3628 - val_accuracy: 0.8696\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 19s 45ms/step - loss: 0.0800 - accuracy: 0.9721 - val_loss: 0.4791 - val_accuracy: 0.8578\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 18s 44ms/step - loss: 0.0374 - accuracy: 0.9861 - val_loss: 0.7043 - val_accuracy: 0.8532\n",
      "209/209 [==============================] - 8s 32ms/step - loss: 0.3099 - accuracy: 0.8762\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 3s 5ms/step - loss: 0.4886 - accuracy: 0.8278 - val_loss: 0.3920 - val_accuracy: 0.8704\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3286 - accuracy: 0.8999 - val_loss: 0.3360 - val_accuracy: 0.8836\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2695 - accuracy: 0.9188 - val_loss: 0.3134 - val_accuracy: 0.8880\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2331 - accuracy: 0.9312 - val_loss: 0.3015 - val_accuracy: 0.8890\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2066 - accuracy: 0.9423 - val_loss: 0.2945 - val_accuracy: 0.8870\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1859 - accuracy: 0.9499 - val_loss: 0.2924 - val_accuracy: 0.8846\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1688 - accuracy: 0.9560 - val_loss: 0.2908 - val_accuracy: 0.8850\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1547 - accuracy: 0.9613 - val_loss: 0.2917 - val_accuracy: 0.8836\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1425 - accuracy: 0.9658 - val_loss: 0.2939 - val_accuracy: 0.8822\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1316 - accuracy: 0.9695 - val_loss: 0.2967 - val_accuracy: 0.8802\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.2854 - accuracy: 0.8865\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 3s 5ms/step - loss: 0.4818 - accuracy: 0.8303 - val_loss: 0.3886 - val_accuracy: 0.8712\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3233 - accuracy: 0.8996 - val_loss: 0.3345 - val_accuracy: 0.8802\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2640 - accuracy: 0.9212 - val_loss: 0.3111 - val_accuracy: 0.8862\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.2275 - accuracy: 0.9351 - val_loss: 0.3001 - val_accuracy: 0.8858\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2014 - accuracy: 0.9431 - val_loss: 0.2945 - val_accuracy: 0.8852\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1809 - accuracy: 0.9518 - val_loss: 0.2906 - val_accuracy: 0.8868\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1642 - accuracy: 0.9580 - val_loss: 0.2910 - val_accuracy: 0.8842\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1503 - accuracy: 0.9615 - val_loss: 0.2908 - val_accuracy: 0.8858\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1381 - accuracy: 0.9664 - val_loss: 0.2917 - val_accuracy: 0.8844\n",
      "209/209 [==============================] - 2s 4ms/step - loss: 0.3014 - accuracy: 0.8833\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 5s 8ms/step - loss: 0.4865 - accuracy: 0.8257 - val_loss: 0.3912 - val_accuracy: 0.8730\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3263 - accuracy: 0.8988 - val_loss: 0.3344 - val_accuracy: 0.8810\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2677 - accuracy: 0.9163 - val_loss: 0.3113 - val_accuracy: 0.8854\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2315 - accuracy: 0.9297 - val_loss: 0.3006 - val_accuracy: 0.8864\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2056 - accuracy: 0.9394 - val_loss: 0.2951 - val_accuracy: 0.8830\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1852 - accuracy: 0.9470 - val_loss: 0.2920 - val_accuracy: 0.8848\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1687 - accuracy: 0.9542 - val_loss: 0.2913 - val_accuracy: 0.8850\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1543 - accuracy: 0.9605 - val_loss: 0.2916 - val_accuracy: 0.8846\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 3s 6ms/step - loss: 0.1422 - accuracy: 0.9654 - val_loss: 0.2942 - val_accuracy: 0.8840\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1316 - accuracy: 0.9690 - val_loss: 0.2968 - val_accuracy: 0.8836\n",
      "209/209 [==============================] - 2s 3ms/step - loss: 0.2918 - accuracy: 0.8866\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 5s 5ms/step - loss: 0.4883 - accuracy: 0.8276 - val_loss: 0.3909 - val_accuracy: 0.8722\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3288 - accuracy: 0.9008 - val_loss: 0.3374 - val_accuracy: 0.8816\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2698 - accuracy: 0.9202 - val_loss: 0.3139 - val_accuracy: 0.8842\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2329 - accuracy: 0.9314 - val_loss: 0.3010 - val_accuracy: 0.8864\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2067 - accuracy: 0.9412 - val_loss: 0.2950 - val_accuracy: 0.8872\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1861 - accuracy: 0.9497 - val_loss: 0.2924 - val_accuracy: 0.8854\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1691 - accuracy: 0.9562 - val_loss: 0.2914 - val_accuracy: 0.8838\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1548 - accuracy: 0.9613 - val_loss: 0.2927 - val_accuracy: 0.8818\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1423 - accuracy: 0.9662 - val_loss: 0.2941 - val_accuracy: 0.8818\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1315 - accuracy: 0.9704 - val_loss: 0.2968 - val_accuracy: 0.8806\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.2864 - accuracy: 0.8846\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 9s 5ms/step - loss: 0.4889 - accuracy: 0.8224 - val_loss: 0.3921 - val_accuracy: 0.8698\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3252 - accuracy: 0.9008 - val_loss: 0.3368 - val_accuracy: 0.8788\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2651 - accuracy: 0.9188 - val_loss: 0.3124 - val_accuracy: 0.8872\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2286 - accuracy: 0.9338 - val_loss: 0.3000 - val_accuracy: 0.8876\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2022 - accuracy: 0.9435 - val_loss: 0.2940 - val_accuracy: 0.8848\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1816 - accuracy: 0.9510 - val_loss: 0.2901 - val_accuracy: 0.8866\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1648 - accuracy: 0.9560 - val_loss: 0.2892 - val_accuracy: 0.8870\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1507 - accuracy: 0.9624 - val_loss: 0.2898 - val_accuracy: 0.8864\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1386 - accuracy: 0.9663 - val_loss: 0.2915 - val_accuracy: 0.8858\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1278 - accuracy: 0.9717 - val_loss: 0.2944 - val_accuracy: 0.8834\n",
      "209/209 [==============================] - 1s 3ms/step - loss: 0.3001 - accuracy: 0.8822\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 3s 5ms/step - loss: 0.4837 - accuracy: 0.8286 - val_loss: 0.3891 - val_accuracy: 0.8738\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3253 - accuracy: 0.8993 - val_loss: 0.3350 - val_accuracy: 0.8808\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 3s 6ms/step - loss: 0.2669 - accuracy: 0.9177 - val_loss: 0.3122 - val_accuracy: 0.8838\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2313 - accuracy: 0.9298 - val_loss: 0.3009 - val_accuracy: 0.8842\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2052 - accuracy: 0.9395 - val_loss: 0.2956 - val_accuracy: 0.8842\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1850 - accuracy: 0.9477 - val_loss: 0.2929 - val_accuracy: 0.8864\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1682 - accuracy: 0.9555 - val_loss: 0.2952 - val_accuracy: 0.8824\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1543 - accuracy: 0.9610 - val_loss: 0.2949 - val_accuracy: 0.8848\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1421 - accuracy: 0.9651 - val_loss: 0.2962 - val_accuracy: 0.8828\n",
      "209/209 [==============================] - 3s 3ms/step - loss: 0.2931 - accuracy: 0.8878\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 3s 5ms/step - loss: 0.4881 - accuracy: 0.8237 - val_loss: 0.3919 - val_accuracy: 0.8730\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3286 - accuracy: 0.9021 - val_loss: 0.3358 - val_accuracy: 0.8822\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2696 - accuracy: 0.9200 - val_loss: 0.3129 - val_accuracy: 0.8856\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2330 - accuracy: 0.9311 - val_loss: 0.3015 - val_accuracy: 0.8884\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2065 - accuracy: 0.9416 - val_loss: 0.2945 - val_accuracy: 0.8882\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1859 - accuracy: 0.9488 - val_loss: 0.2915 - val_accuracy: 0.8870\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1688 - accuracy: 0.9559 - val_loss: 0.2916 - val_accuracy: 0.8854\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1546 - accuracy: 0.9612 - val_loss: 0.2923 - val_accuracy: 0.8842\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1424 - accuracy: 0.9660 - val_loss: 0.2935 - val_accuracy: 0.8846\n",
      "209/209 [==============================] - 2s 4ms/step - loss: 0.2874 - accuracy: 0.8865\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 4s 6ms/step - loss: 0.4868 - accuracy: 0.8255 - val_loss: 0.3911 - val_accuracy: 0.8702\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3245 - accuracy: 0.9004 - val_loss: 0.3351 - val_accuracy: 0.8804\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2648 - accuracy: 0.9209 - val_loss: 0.3112 - val_accuracy: 0.8850\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.2284 - accuracy: 0.9326 - val_loss: 0.3006 - val_accuracy: 0.8842\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 3s 8ms/step - loss: 0.2020 - accuracy: 0.9432 - val_loss: 0.2938 - val_accuracy: 0.8846\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1817 - accuracy: 0.9509 - val_loss: 0.2898 - val_accuracy: 0.8872\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1649 - accuracy: 0.9564 - val_loss: 0.2895 - val_accuracy: 0.8858\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1508 - accuracy: 0.9619 - val_loss: 0.2904 - val_accuracy: 0.8840\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.1386 - accuracy: 0.9666 - val_loss: 0.2923 - val_accuracy: 0.8850\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1279 - accuracy: 0.9708 - val_loss: 0.2945 - val_accuracy: 0.8834\n",
      "209/209 [==============================] - 2s 4ms/step - loss: 0.3003 - accuracy: 0.8821\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 4s 6ms/step - loss: 0.4865 - accuracy: 0.8241 - val_loss: 0.3908 - val_accuracy: 0.8698\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3264 - accuracy: 0.8991 - val_loss: 0.3365 - val_accuracy: 0.8794\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2682 - accuracy: 0.9167 - val_loss: 0.3127 - val_accuracy: 0.8836\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2321 - accuracy: 0.9296 - val_loss: 0.3013 - val_accuracy: 0.8828\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2059 - accuracy: 0.9381 - val_loss: 0.2961 - val_accuracy: 0.8818\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1856 - accuracy: 0.9477 - val_loss: 0.2934 - val_accuracy: 0.8834\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1689 - accuracy: 0.9546 - val_loss: 0.2943 - val_accuracy: 0.8834\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1549 - accuracy: 0.9602 - val_loss: 0.2931 - val_accuracy: 0.8838\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1427 - accuracy: 0.9651 - val_loss: 0.2946 - val_accuracy: 0.8834\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.1319 - accuracy: 0.9695 - val_loss: 0.2983 - val_accuracy: 0.8814\n",
      "Epoch 11/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1224 - accuracy: 0.9731 - val_loss: 0.3006 - val_accuracy: 0.8814\n",
      "209/209 [==============================] - 2s 4ms/step - loss: 0.2920 - accuracy: 0.8860\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 13s 6ms/step - loss: 0.4885 - accuracy: 0.8246 - val_loss: 0.3919 - val_accuracy: 0.8694\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.3282 - accuracy: 0.9008 - val_loss: 0.3364 - val_accuracy: 0.8816\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2694 - accuracy: 0.9182 - val_loss: 0.3131 - val_accuracy: 0.8854\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 3s 6ms/step - loss: 0.2329 - accuracy: 0.9317 - val_loss: 0.3014 - val_accuracy: 0.8874\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2063 - accuracy: 0.9419 - val_loss: 0.2956 - val_accuracy: 0.8866\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.1856 - accuracy: 0.9501 - val_loss: 0.2916 - val_accuracy: 0.8846\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 4s 10ms/step - loss: 0.1689 - accuracy: 0.9562 - val_loss: 0.2915 - val_accuracy: 0.8834\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1545 - accuracy: 0.9611 - val_loss: 0.2926 - val_accuracy: 0.8802\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1423 - accuracy: 0.9660 - val_loss: 0.2944 - val_accuracy: 0.8806\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1315 - accuracy: 0.9708 - val_loss: 0.2973 - val_accuracy: 0.8804\n",
      "209/209 [==============================] - 2s 4ms/step - loss: 0.2856 - accuracy: 0.8864\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 4s 5ms/step - loss: 0.4834 - accuracy: 0.8307 - val_loss: 0.3908 - val_accuracy: 0.8716\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3234 - accuracy: 0.9010 - val_loss: 0.3358 - val_accuracy: 0.8830\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2644 - accuracy: 0.9203 - val_loss: 0.3126 - val_accuracy: 0.8854\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2281 - accuracy: 0.9332 - val_loss: 0.3011 - val_accuracy: 0.8842\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2020 - accuracy: 0.9438 - val_loss: 0.2944 - val_accuracy: 0.8866\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1813 - accuracy: 0.9518 - val_loss: 0.2923 - val_accuracy: 0.8848\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1645 - accuracy: 0.9572 - val_loss: 0.2906 - val_accuracy: 0.8860\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1504 - accuracy: 0.9623 - val_loss: 0.2909 - val_accuracy: 0.8854\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1384 - accuracy: 0.9665 - val_loss: 0.2944 - val_accuracy: 0.8822\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1277 - accuracy: 0.9708 - val_loss: 0.2961 - val_accuracy: 0.8808\n",
      "209/209 [==============================] - 2s 3ms/step - loss: 0.3008 - accuracy: 0.8840\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 3s 5ms/step - loss: 0.4887 - accuracy: 0.8228 - val_loss: 0.3930 - val_accuracy: 0.8722\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3264 - accuracy: 0.8994 - val_loss: 0.3365 - val_accuracy: 0.8838\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2677 - accuracy: 0.9179 - val_loss: 0.3136 - val_accuracy: 0.8844\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2318 - accuracy: 0.9310 - val_loss: 0.3013 - val_accuracy: 0.8858\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2056 - accuracy: 0.9397 - val_loss: 0.2953 - val_accuracy: 0.8856\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1855 - accuracy: 0.9477 - val_loss: 0.2930 - val_accuracy: 0.8848\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1686 - accuracy: 0.9554 - val_loss: 0.2923 - val_accuracy: 0.8838\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1545 - accuracy: 0.9606 - val_loss: 0.2928 - val_accuracy: 0.8832\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1425 - accuracy: 0.9654 - val_loss: 0.2945 - val_accuracy: 0.8822\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1317 - accuracy: 0.9695 - val_loss: 0.2974 - val_accuracy: 0.8804\n",
      "209/209 [==============================] - 2s 4ms/step - loss: 0.2917 - accuracy: 0.8883\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 7s 12ms/step - loss: 0.3694 - accuracy: 0.8428 - val_loss: 0.2916 - val_accuracy: 0.8844\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.1425 - accuracy: 0.9439 - val_loss: 0.3531 - val_accuracy: 0.8734\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.0409 - accuracy: 0.9855 - val_loss: 0.6017 - val_accuracy: 0.8608\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 4s 11ms/step - loss: 0.0228 - accuracy: 0.9934 - val_loss: 0.6404 - val_accuracy: 0.8616\n",
      "209/209 [==============================] - 2s 5ms/step - loss: 0.2931 - accuracy: 0.8803\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 7s 11ms/step - loss: 0.3590 - accuracy: 0.8414 - val_loss: 0.3002 - val_accuracy: 0.8786\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 4s 11ms/step - loss: 0.1396 - accuracy: 0.9462 - val_loss: 0.3646 - val_accuracy: 0.8666\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.0368 - accuracy: 0.9878 - val_loss: 0.5195 - val_accuracy: 0.8568\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.0190 - accuracy: 0.9950 - val_loss: 0.7489 - val_accuracy: 0.8672\n",
      "209/209 [==============================] - 8s 5ms/step - loss: 0.3120 - accuracy: 0.8713\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 6s 11ms/step - loss: 0.3676 - accuracy: 0.8432 - val_loss: 0.3124 - val_accuracy: 0.8720\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 4s 10ms/step - loss: 0.1361 - accuracy: 0.9481 - val_loss: 0.3762 - val_accuracy: 0.8648\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.0354 - accuracy: 0.9881 - val_loss: 0.5517 - val_accuracy: 0.8582\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.0144 - accuracy: 0.9954 - val_loss: 0.7713 - val_accuracy: 0.8632\n",
      "209/209 [==============================] - 3s 6ms/step - loss: 0.3100 - accuracy: 0.8744\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 6s 8ms/step - loss: 0.4902 - accuracy: 0.8266 - val_loss: 0.3933 - val_accuracy: 0.8696\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3293 - accuracy: 0.9006 - val_loss: 0.3367 - val_accuracy: 0.8810\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2698 - accuracy: 0.9207 - val_loss: 0.3123 - val_accuracy: 0.8870\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2329 - accuracy: 0.9325 - val_loss: 0.3003 - val_accuracy: 0.8876\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2064 - accuracy: 0.9427 - val_loss: 0.2934 - val_accuracy: 0.8904\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1859 - accuracy: 0.9497 - val_loss: 0.2911 - val_accuracy: 0.8872\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1691 - accuracy: 0.9547 - val_loss: 0.2902 - val_accuracy: 0.8858\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1545 - accuracy: 0.9620 - val_loss: 0.2909 - val_accuracy: 0.8848\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1422 - accuracy: 0.9661 - val_loss: 0.2949 - val_accuracy: 0.8816\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1315 - accuracy: 0.9708 - val_loss: 0.2957 - val_accuracy: 0.8820\n",
      "209/209 [==============================] - 2s 3ms/step - loss: 0.2857 - accuracy: 0.8864\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 3s 5ms/step - loss: 0.4849 - accuracy: 0.8272 - val_loss: 0.3917 - val_accuracy: 0.8706\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3240 - accuracy: 0.9017 - val_loss: 0.3356 - val_accuracy: 0.8840\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2645 - accuracy: 0.9215 - val_loss: 0.3125 - val_accuracy: 0.8856\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2281 - accuracy: 0.9344 - val_loss: 0.3000 - val_accuracy: 0.8884\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2018 - accuracy: 0.9437 - val_loss: 0.2935 - val_accuracy: 0.8862\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1811 - accuracy: 0.9523 - val_loss: 0.2909 - val_accuracy: 0.8856\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1645 - accuracy: 0.9569 - val_loss: 0.2901 - val_accuracy: 0.8864\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.1504 - accuracy: 0.9623 - val_loss: 0.2902 - val_accuracy: 0.8854\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.1384 - accuracy: 0.9665 - val_loss: 0.2913 - val_accuracy: 0.8866\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.1277 - accuracy: 0.9716 - val_loss: 0.2936 - val_accuracy: 0.8858\n",
      "209/209 [==============================] - 2s 4ms/step - loss: 0.3001 - accuracy: 0.8827\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 4s 6ms/step - loss: 0.4854 - accuracy: 0.8276 - val_loss: 0.3911 - val_accuracy: 0.8702\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3266 - accuracy: 0.8994 - val_loss: 0.3365 - val_accuracy: 0.8790\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2680 - accuracy: 0.9187 - val_loss: 0.3134 - val_accuracy: 0.8840\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2321 - accuracy: 0.9306 - val_loss: 0.3011 - val_accuracy: 0.8844\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2058 - accuracy: 0.9396 - val_loss: 0.2957 - val_accuracy: 0.8848\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1854 - accuracy: 0.9480 - val_loss: 0.2929 - val_accuracy: 0.8858\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1688 - accuracy: 0.9549 - val_loss: 0.2924 - val_accuracy: 0.8834\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1546 - accuracy: 0.9608 - val_loss: 0.2935 - val_accuracy: 0.8834\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1425 - accuracy: 0.9651 - val_loss: 0.2947 - val_accuracy: 0.8834\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.1318 - accuracy: 0.9694 - val_loss: 0.2971 - val_accuracy: 0.8818\n",
      "209/209 [==============================] - 2s 4ms/step - loss: 0.2914 - accuracy: 0.8881\n",
      "Epoch 1/20\n",
      "625/625 [==============================] - 5s 5ms/step - loss: 0.4460 - accuracy: 0.8456 - val_loss: 0.3534 - val_accuracy: 0.8782\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.2977 - accuracy: 0.9041 - val_loss: 0.3094 - val_accuracy: 0.8868\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.2476 - accuracy: 0.9201 - val_loss: 0.2910 - val_accuracy: 0.8924\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.2171 - accuracy: 0.9302 - val_loss: 0.2837 - val_accuracy: 0.8906\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1949 - accuracy: 0.9401 - val_loss: 0.2807 - val_accuracy: 0.8896\n",
      "Epoch 6/20\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1773 - accuracy: 0.9462 - val_loss: 0.2807 - val_accuracy: 0.8890\n",
      "Epoch 7/20\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1631 - accuracy: 0.9513 - val_loss: 0.2825 - val_accuracy: 0.8888\n",
      "Epoch 8/20\n",
      "625/625 [==============================] - 2s 4ms/step - loss: 0.1510 - accuracy: 0.9558 - val_loss: 0.2850 - val_accuracy: 0.8900\n",
      "Epoch 9/20\n",
      "625/625 [==============================] - 3s 4ms/step - loss: 0.1407 - accuracy: 0.9603 - val_loss: 0.2892 - val_accuracy: 0.8874\n",
      "TF-IDF:\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 10s 20ms/step - loss: 0.4028 - accuracy: 0.8480 - val_loss: 0.2744 - val_accuracy: 0.8894\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.1523 - accuracy: 0.9530 - val_loss: 0.2803 - val_accuracy: 0.8840\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0700 - accuracy: 0.9846 - val_loss: 0.3139 - val_accuracy: 0.8758\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.0313 - accuracy: 0.9963 - val_loss: 0.3518 - val_accuracy: 0.8748\n",
      "209/209 [==============================] - 2s 6ms/step - loss: 0.2666 - accuracy: 0.8928\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 10s 19ms/step - loss: 0.4001 - accuracy: 0.8567 - val_loss: 0.2736 - val_accuracy: 0.8888\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 6s 13ms/step - loss: 0.1490 - accuracy: 0.9527 - val_loss: 0.2769 - val_accuracy: 0.8836\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.0689 - accuracy: 0.9848 - val_loss: 0.3099 - val_accuracy: 0.8764\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0313 - accuracy: 0.9965 - val_loss: 0.3473 - val_accuracy: 0.8698\n",
      "209/209 [==============================] - 3s 6ms/step - loss: 0.2793 - accuracy: 0.8847\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 13s 26ms/step - loss: 0.4014 - accuracy: 0.8430 - val_loss: 0.2779 - val_accuracy: 0.8868\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 6s 15ms/step - loss: 0.1506 - accuracy: 0.9507 - val_loss: 0.2790 - val_accuracy: 0.8846\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 6s 15ms/step - loss: 0.0669 - accuracy: 0.9861 - val_loss: 0.3139 - val_accuracy: 0.8822\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 7s 16ms/step - loss: 0.0290 - accuracy: 0.9969 - val_loss: 0.3526 - val_accuracy: 0.8786\n",
      "209/209 [==============================] - 3s 7ms/step - loss: 0.2761 - accuracy: 0.8889\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 16s 34ms/step - loss: 0.6624 - accuracy: 0.8099 - val_loss: 0.6324 - val_accuracy: 0.8570\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 3s 6ms/step - loss: 0.6001 - accuracy: 0.8785 - val_loss: 0.5835 - val_accuracy: 0.8630\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.5490 - accuracy: 0.8870 - val_loss: 0.5435 - val_accuracy: 0.8652\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.5066 - accuracy: 0.8942 - val_loss: 0.5105 - val_accuracy: 0.8674\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.4710 - accuracy: 0.8984 - val_loss: 0.4829 - val_accuracy: 0.8698\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 4s 10ms/step - loss: 0.4407 - accuracy: 0.9034 - val_loss: 0.4593 - val_accuracy: 0.8716\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.4144 - accuracy: 0.9080 - val_loss: 0.4391 - val_accuracy: 0.8732\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3915 - accuracy: 0.9122 - val_loss: 0.4221 - val_accuracy: 0.8750\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3712 - accuracy: 0.9170 - val_loss: 0.4066 - val_accuracy: 0.8764\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3531 - accuracy: 0.9200 - val_loss: 0.3932 - val_accuracy: 0.8782\n",
      "Epoch 11/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3369 - accuracy: 0.9242 - val_loss: 0.3817 - val_accuracy: 0.8780\n",
      "Epoch 12/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3222 - accuracy: 0.9268 - val_loss: 0.3709 - val_accuracy: 0.8802\n",
      "Epoch 13/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3089 - accuracy: 0.9302 - val_loss: 0.3616 - val_accuracy: 0.8812\n",
      "Epoch 14/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2966 - accuracy: 0.9332 - val_loss: 0.3533 - val_accuracy: 0.8826\n",
      "Epoch 15/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2854 - accuracy: 0.9356 - val_loss: 0.3457 - val_accuracy: 0.8832\n",
      "Epoch 16/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2750 - accuracy: 0.9384 - val_loss: 0.3389 - val_accuracy: 0.8858\n",
      "Epoch 17/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2654 - accuracy: 0.9401 - val_loss: 0.3327 - val_accuracy: 0.8868\n",
      "Epoch 18/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2565 - accuracy: 0.9430 - val_loss: 0.3272 - val_accuracy: 0.8868\n",
      "Epoch 19/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2481 - accuracy: 0.9449 - val_loss: 0.3223 - val_accuracy: 0.8878\n",
      "Epoch 20/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2403 - accuracy: 0.9467 - val_loss: 0.3176 - val_accuracy: 0.8888\n",
      "209/209 [==============================] - 2s 3ms/step - loss: 0.3140 - accuracy: 0.8882\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 21s 45ms/step - loss: 0.6614 - accuracy: 0.8010 - val_loss: 0.6316 - val_accuracy: 0.8540\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.5978 - accuracy: 0.8766 - val_loss: 0.5824 - val_accuracy: 0.8624\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.5460 - accuracy: 0.8861 - val_loss: 0.5428 - val_accuracy: 0.8660\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.5033 - accuracy: 0.8921 - val_loss: 0.5098 - val_accuracy: 0.8674\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.4675 - accuracy: 0.8977 - val_loss: 0.4824 - val_accuracy: 0.8692\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.4370 - accuracy: 0.9025 - val_loss: 0.4590 - val_accuracy: 0.8730\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.4108 - accuracy: 0.9074 - val_loss: 0.4388 - val_accuracy: 0.8744\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3878 - accuracy: 0.9121 - val_loss: 0.4214 - val_accuracy: 0.8754\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3676 - accuracy: 0.9163 - val_loss: 0.4065 - val_accuracy: 0.8774\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3494 - accuracy: 0.9190 - val_loss: 0.3930 - val_accuracy: 0.8792\n",
      "Epoch 11/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3333 - accuracy: 0.9239 - val_loss: 0.3815 - val_accuracy: 0.8800\n",
      "Epoch 12/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3187 - accuracy: 0.9272 - val_loss: 0.3710 - val_accuracy: 0.8814\n",
      "Epoch 13/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3053 - accuracy: 0.9305 - val_loss: 0.3618 - val_accuracy: 0.8814\n",
      "Epoch 14/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2931 - accuracy: 0.9335 - val_loss: 0.3533 - val_accuracy: 0.8834\n",
      "Epoch 15/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2819 - accuracy: 0.9370 - val_loss: 0.3460 - val_accuracy: 0.8832\n",
      "Epoch 16/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2716 - accuracy: 0.9386 - val_loss: 0.3391 - val_accuracy: 0.8844\n",
      "Epoch 17/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2621 - accuracy: 0.9420 - val_loss: 0.3330 - val_accuracy: 0.8868\n",
      "Epoch 18/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2532 - accuracy: 0.9441 - val_loss: 0.3276 - val_accuracy: 0.8874\n",
      "Epoch 19/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2449 - accuracy: 0.9459 - val_loss: 0.3226 - val_accuracy: 0.8874\n",
      "Epoch 20/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.2371 - accuracy: 0.9477 - val_loss: 0.3182 - val_accuracy: 0.8886\n",
      "209/209 [==============================] - 2s 3ms/step - loss: 0.3229 - accuracy: 0.8819\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 7s 12ms/step - loss: 0.6625 - accuracy: 0.8076 - val_loss: 0.6330 - val_accuracy: 0.8550\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.6000 - accuracy: 0.8740 - val_loss: 0.5840 - val_accuracy: 0.8606\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.5488 - accuracy: 0.8832 - val_loss: 0.5442 - val_accuracy: 0.8630\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.5065 - accuracy: 0.8911 - val_loss: 0.5113 - val_accuracy: 0.8660\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.4710 - accuracy: 0.8958 - val_loss: 0.4838 - val_accuracy: 0.8684\n",
      "Epoch 6/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.4408 - accuracy: 0.9012 - val_loss: 0.4605 - val_accuracy: 0.8708\n",
      "Epoch 7/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.4147 - accuracy: 0.9051 - val_loss: 0.4405 - val_accuracy: 0.8728\n",
      "Epoch 8/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3919 - accuracy: 0.9095 - val_loss: 0.4233 - val_accuracy: 0.8744\n",
      "Epoch 9/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3717 - accuracy: 0.9134 - val_loss: 0.4079 - val_accuracy: 0.8766\n",
      "Epoch 10/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3537 - accuracy: 0.9185 - val_loss: 0.3947 - val_accuracy: 0.8762\n",
      "Epoch 11/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.3375 - accuracy: 0.9204 - val_loss: 0.3827 - val_accuracy: 0.8788\n",
      "Epoch 12/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3228 - accuracy: 0.9246 - val_loss: 0.3723 - val_accuracy: 0.8788\n",
      "Epoch 13/20\n",
      "417/417 [==============================] - 2s 4ms/step - loss: 0.3094 - accuracy: 0.9285 - val_loss: 0.3629 - val_accuracy: 0.8818\n",
      "Epoch 14/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2972 - accuracy: 0.9305 - val_loss: 0.3545 - val_accuracy: 0.8826\n",
      "Epoch 15/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2859 - accuracy: 0.9345 - val_loss: 0.3469 - val_accuracy: 0.8826\n",
      "Epoch 16/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2756 - accuracy: 0.9372 - val_loss: 0.3402 - val_accuracy: 0.8834\n",
      "Epoch 17/20\n",
      "417/417 [==============================] - 2s 5ms/step - loss: 0.2659 - accuracy: 0.9390 - val_loss: 0.3339 - val_accuracy: 0.8838\n",
      "Epoch 18/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.2570 - accuracy: 0.9424 - val_loss: 0.3283 - val_accuracy: 0.8842\n",
      "Epoch 19/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.2486 - accuracy: 0.9447 - val_loss: 0.3231 - val_accuracy: 0.8846\n",
      "Epoch 20/20\n",
      "417/417 [==============================] - 2s 6ms/step - loss: 0.2408 - accuracy: 0.9471 - val_loss: 0.3184 - val_accuracy: 0.8860\n",
      "209/209 [==============================] - 2s 4ms/step - loss: 0.3162 - accuracy: 0.8907\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 16s 28ms/step - loss: 0.4379 - accuracy: 0.8492 - val_loss: 0.2876 - val_accuracy: 0.8942\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.1769 - accuracy: 0.9419 - val_loss: 0.2686 - val_accuracy: 0.8920\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 7s 16ms/step - loss: 0.0913 - accuracy: 0.9783 - val_loss: 0.2902 - val_accuracy: 0.8838\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0475 - accuracy: 0.9925 - val_loss: 0.3179 - val_accuracy: 0.8784\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.0251 - accuracy: 0.9980 - val_loss: 0.3514 - val_accuracy: 0.8754\n",
      "209/209 [==============================] - 3s 7ms/step - loss: 0.2611 - accuracy: 0.8898\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 13s 26ms/step - loss: 0.4300 - accuracy: 0.8502 - val_loss: 0.2863 - val_accuracy: 0.8898\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 4s 11ms/step - loss: 0.1735 - accuracy: 0.9422 - val_loss: 0.2701 - val_accuracy: 0.8862\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 4s 10ms/step - loss: 0.0895 - accuracy: 0.9787 - val_loss: 0.2894 - val_accuracy: 0.8822\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0468 - accuracy: 0.9934 - val_loss: 0.3184 - val_accuracy: 0.8758\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 4s 10ms/step - loss: 0.0250 - accuracy: 0.9974 - val_loss: 0.3460 - val_accuracy: 0.8722\n",
      "209/209 [==============================] - 3s 6ms/step - loss: 0.2757 - accuracy: 0.8846\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 8s 14ms/step - loss: 0.4345 - accuracy: 0.8398 - val_loss: 0.2875 - val_accuracy: 0.8866\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.1751 - accuracy: 0.9426 - val_loss: 0.2732 - val_accuracy: 0.8904\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 5s 11ms/step - loss: 0.0898 - accuracy: 0.9783 - val_loss: 0.2891 - val_accuracy: 0.8830\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0456 - accuracy: 0.9937 - val_loss: 0.3221 - val_accuracy: 0.8814\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 4s 10ms/step - loss: 0.0237 - accuracy: 0.9984 - val_loss: 0.3470 - val_accuracy: 0.8800\n",
      "209/209 [==============================] - 4s 6ms/step - loss: 0.2672 - accuracy: 0.8897\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 22s 48ms/step - loss: 0.4281 - accuracy: 0.8519 - val_loss: 0.2872 - val_accuracy: 0.8882\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.1700 - accuracy: 0.9455 - val_loss: 0.2712 - val_accuracy: 0.8866\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0855 - accuracy: 0.9803 - val_loss: 0.3025 - val_accuracy: 0.8808\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 4s 10ms/step - loss: 0.0434 - accuracy: 0.9932 - val_loss: 0.3268 - val_accuracy: 0.8774\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.0222 - accuracy: 0.9983 - val_loss: 0.3580 - val_accuracy: 0.8752\n",
      "209/209 [==============================] - 4s 8ms/step - loss: 0.2622 - accuracy: 0.8882\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 36s 80ms/step - loss: 0.4263 - accuracy: 0.8418 - val_loss: 0.2846 - val_accuracy: 0.8876\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 7s 17ms/step - loss: 0.1685 - accuracy: 0.9455 - val_loss: 0.2693 - val_accuracy: 0.8872\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 8s 19ms/step - loss: 0.0848 - accuracy: 0.9802 - val_loss: 0.2931 - val_accuracy: 0.8840\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 6s 15ms/step - loss: 0.0434 - accuracy: 0.9933 - val_loss: 0.3243 - val_accuracy: 0.8734\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 6s 15ms/step - loss: 0.0227 - accuracy: 0.9977 - val_loss: 0.3600 - val_accuracy: 0.8722\n",
      "209/209 [==============================] - 4s 11ms/step - loss: 0.2755 - accuracy: 0.8828\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 10s 18ms/step - loss: 0.4268 - accuracy: 0.8441 - val_loss: 0.2844 - val_accuracy: 0.8882\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.1701 - accuracy: 0.9453 - val_loss: 0.2710 - val_accuracy: 0.8914\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0842 - accuracy: 0.9810 - val_loss: 0.2944 - val_accuracy: 0.8856\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 6s 15ms/step - loss: 0.0413 - accuracy: 0.9945 - val_loss: 0.3312 - val_accuracy: 0.8814\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0210 - accuracy: 0.9988 - val_loss: 0.3545 - val_accuracy: 0.8816\n",
      "209/209 [==============================] - 4s 10ms/step - loss: 0.2668 - accuracy: 0.8884\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 15s 33ms/step - loss: 0.4285 - accuracy: 0.8406 - val_loss: 0.2891 - val_accuracy: 0.8854\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 8s 20ms/step - loss: 0.1720 - accuracy: 0.9441 - val_loss: 0.2715 - val_accuracy: 0.8856\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 8s 18ms/step - loss: 0.0875 - accuracy: 0.9800 - val_loss: 0.2956 - val_accuracy: 0.8816\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 7s 17ms/step - loss: 0.0449 - accuracy: 0.9927 - val_loss: 0.3269 - val_accuracy: 0.8772\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 7s 17ms/step - loss: 0.0229 - accuracy: 0.9982 - val_loss: 0.3596 - val_accuracy: 0.8752\n",
      "209/209 [==============================] - 5s 12ms/step - loss: 0.2606 - accuracy: 0.8892\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 11s 21ms/step - loss: 0.4230 - accuracy: 0.8541 - val_loss: 0.2849 - val_accuracy: 0.8874\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 8s 20ms/step - loss: 0.1697 - accuracy: 0.9454 - val_loss: 0.2682 - val_accuracy: 0.8866\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 7s 16ms/step - loss: 0.0869 - accuracy: 0.9790 - val_loss: 0.2911 - val_accuracy: 0.8800\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.0449 - accuracy: 0.9932 - val_loss: 0.3173 - val_accuracy: 0.8754\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 5s 12ms/step - loss: 0.0236 - accuracy: 0.9974 - val_loss: 0.3477 - val_accuracy: 0.8702\n",
      "209/209 [==============================] - 3s 7ms/step - loss: 0.2748 - accuracy: 0.8862\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 31s 11ms/step - loss: 0.4293 - accuracy: 0.8490 - val_loss: 0.2862 - val_accuracy: 0.8874\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.1723 - accuracy: 0.9435 - val_loss: 0.2696 - val_accuracy: 0.8908\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.0856 - accuracy: 0.9806 - val_loss: 0.2915 - val_accuracy: 0.8834\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.0430 - accuracy: 0.9947 - val_loss: 0.3230 - val_accuracy: 0.8816\n",
      "Epoch 5/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.0217 - accuracy: 0.9984 - val_loss: 0.3514 - val_accuracy: 0.8818\n",
      "209/209 [==============================] - 2s 5ms/step - loss: 0.2640 - accuracy: 0.8902\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 9s 18ms/step - loss: 0.3946 - accuracy: 0.8487 - val_loss: 0.2754 - val_accuracy: 0.8872\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.1178 - accuracy: 0.9628 - val_loss: 0.3231 - val_accuracy: 0.8736\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 3s 8ms/step - loss: 0.0397 - accuracy: 0.9917 - val_loss: 0.4201 - val_accuracy: 0.8670\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.0141 - accuracy: 0.9979 - val_loss: 0.4879 - val_accuracy: 0.8680\n",
      "209/209 [==============================] - 2s 4ms/step - loss: 0.2699 - accuracy: 0.8846\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 12s 27ms/step - loss: 0.4101 - accuracy: 0.8207 - val_loss: 0.2782 - val_accuracy: 0.8842\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.1252 - accuracy: 0.9581 - val_loss: 0.3273 - val_accuracy: 0.8712\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.0389 - accuracy: 0.9915 - val_loss: 0.4175 - val_accuracy: 0.8650\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 4s 10ms/step - loss: 0.0132 - accuracy: 0.9977 - val_loss: 0.4856 - val_accuracy: 0.8632\n",
      "209/209 [==============================] - 3s 5ms/step - loss: 0.2862 - accuracy: 0.8807\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 23s 45ms/step - loss: 0.4031 - accuracy: 0.8347 - val_loss: 0.2719 - val_accuracy: 0.8888\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.1221 - accuracy: 0.9570 - val_loss: 0.3222 - val_accuracy: 0.8798\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.0362 - accuracy: 0.9916 - val_loss: 0.4062 - val_accuracy: 0.8730\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.0104 - accuracy: 0.9986 - val_loss: 0.4618 - val_accuracy: 0.8720\n",
      "209/209 [==============================] - 3s 5ms/step - loss: 0.2689 - accuracy: 0.8914\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 7s 14ms/step - loss: 0.3756 - accuracy: 0.8487 - val_loss: 0.2729 - val_accuracy: 0.8878\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.1145 - accuracy: 0.9627 - val_loss: 0.3247 - val_accuracy: 0.8734\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 4s 11ms/step - loss: 0.0353 - accuracy: 0.9923 - val_loss: 0.4133 - val_accuracy: 0.8642\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.4790 - val_accuracy: 0.8652\n",
      "209/209 [==============================] - 2s 5ms/step - loss: 0.2639 - accuracy: 0.8895\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 7s 13ms/step - loss: 0.3775 - accuracy: 0.8452 - val_loss: 0.2728 - val_accuracy: 0.8834\n",
      "Epoch 2/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/417 [==============================] - 5s 11ms/step - loss: 0.1133 - accuracy: 0.9622 - val_loss: 0.3329 - val_accuracy: 0.8714\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 7s 16ms/step - loss: 0.0346 - accuracy: 0.9923 - val_loss: 0.4105 - val_accuracy: 0.8660\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 6s 13ms/step - loss: 0.0090 - accuracy: 0.9988 - val_loss: 0.4766 - val_accuracy: 0.8630\n",
      "209/209 [==============================] - 3s 8ms/step - loss: 0.2793 - accuracy: 0.8819\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 9s 19ms/step - loss: 0.3848 - accuracy: 0.8440 - val_loss: 0.2767 - val_accuracy: 0.8848\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 8s 18ms/step - loss: 0.1177 - accuracy: 0.9597 - val_loss: 0.3312 - val_accuracy: 0.8802\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 7s 17ms/step - loss: 0.0340 - accuracy: 0.9927 - val_loss: 0.4068 - val_accuracy: 0.8730\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 7s 16ms/step - loss: 0.0092 - accuracy: 0.9987 - val_loss: 0.4655 - val_accuracy: 0.8716\n",
      "209/209 [==============================] - 2s 6ms/step - loss: 0.2688 - accuracy: 0.8911\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 14s 29ms/step - loss: 0.4039 - accuracy: 0.8270 - val_loss: 0.2869 - val_accuracy: 0.8820\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.1245 - accuracy: 0.9604 - val_loss: 0.3364 - val_accuracy: 0.8706\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 3s 8ms/step - loss: 0.0397 - accuracy: 0.9911 - val_loss: 0.4309 - val_accuracy: 0.8682\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 3s 8ms/step - loss: 0.0138 - accuracy: 0.9972 - val_loss: 0.5011 - val_accuracy: 0.8670\n",
      "209/209 [==============================] - 2s 5ms/step - loss: 0.2801 - accuracy: 0.8819\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 9s 18ms/step - loss: 0.3936 - accuracy: 0.8466 - val_loss: 0.2716 - val_accuracy: 0.8872\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.1191 - accuracy: 0.9599 - val_loss: 0.3135 - val_accuracy: 0.8786\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 3s 8ms/step - loss: 0.0384 - accuracy: 0.9905 - val_loss: 0.4093 - val_accuracy: 0.8682\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.0111 - accuracy: 0.9985 - val_loss: 0.4735 - val_accuracy: 0.8630\n",
      "209/209 [==============================] - 2s 6ms/step - loss: 0.2789 - accuracy: 0.8844\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 22s 13ms/step - loss: 0.4055 - accuracy: 0.8225 - val_loss: 0.2821 - val_accuracy: 0.8834\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.1198 - accuracy: 0.9605 - val_loss: 0.3308 - val_accuracy: 0.8770\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.0347 - accuracy: 0.9924 - val_loss: 0.4344 - val_accuracy: 0.8670\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.0120 - accuracy: 0.9982 - val_loss: 0.4858 - val_accuracy: 0.8682\n",
      "209/209 [==============================] - 2s 5ms/step - loss: 0.2762 - accuracy: 0.8844\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 8s 17ms/step - loss: 0.3923 - accuracy: 0.8519 - val_loss: 0.2700 - val_accuracy: 0.8882\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 3s 8ms/step - loss: 0.1250 - accuracy: 0.9595 - val_loss: 0.3314 - val_accuracy: 0.8716\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 4s 8ms/step - loss: 0.0396 - accuracy: 0.9915 - val_loss: 0.3916 - val_accuracy: 0.8714\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 3s 8ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.4563 - val_accuracy: 0.8682\n",
      "209/209 [==============================] - 1s 5ms/step - loss: 0.2658 - accuracy: 0.8922\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 10s 21ms/step - loss: 0.3898 - accuracy: 0.8519 - val_loss: 0.2723 - val_accuracy: 0.8874\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 4s 10ms/step - loss: 0.1215 - accuracy: 0.9591 - val_loss: 0.3139 - val_accuracy: 0.8752\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.0381 - accuracy: 0.9920 - val_loss: 0.3892 - val_accuracy: 0.8688\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 3s 7ms/step - loss: 0.0113 - accuracy: 0.9986 - val_loss: 0.4501 - val_accuracy: 0.8622\n",
      "209/209 [==============================] - 3s 7ms/step - loss: 0.2744 - accuracy: 0.8865\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 14s 30ms/step - loss: 0.4040 - accuracy: 0.8354 - val_loss: 0.2700 - val_accuracy: 0.8882\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.1290 - accuracy: 0.9555 - val_loss: 0.3087 - val_accuracy: 0.8792\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0396 - accuracy: 0.9917 - val_loss: 0.3834 - val_accuracy: 0.8756\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 4s 9ms/step - loss: 0.0107 - accuracy: 0.9987 - val_loss: 0.4482 - val_accuracy: 0.8724\n",
      "209/209 [==============================] - 2s 6ms/step - loss: 0.2658 - accuracy: 0.8900\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 29s 68ms/step - loss: 0.4005 - accuracy: 0.8457 - val_loss: 0.2734 - val_accuracy: 0.8872\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.1488 - accuracy: 0.9515 - val_loss: 0.2834 - val_accuracy: 0.8822\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0654 - accuracy: 0.9857 - val_loss: 0.3193 - val_accuracy: 0.8780\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 7s 17ms/step - loss: 0.0286 - accuracy: 0.9965 - val_loss: 0.3596 - val_accuracy: 0.8738\n",
      "209/209 [==============================] - 3s 10ms/step - loss: 0.2663 - accuracy: 0.8918\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 7s 15ms/step - loss: 0.3974 - accuracy: 0.8509 - val_loss: 0.2746 - val_accuracy: 0.8898\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.1466 - accuracy: 0.9524 - val_loss: 0.2849 - val_accuracy: 0.8812\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 7s 17ms/step - loss: 0.0662 - accuracy: 0.9860 - val_loss: 0.3130 - val_accuracy: 0.8736\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 6s 14ms/step - loss: 0.0300 - accuracy: 0.9957 - val_loss: 0.3513 - val_accuracy: 0.8714\n",
      "209/209 [==============================] - 2s 8ms/step - loss: 0.2809 - accuracy: 0.8834\n",
      "Epoch 1/20\n",
      "417/417 [==============================] - 10s 19ms/step - loss: 0.4000 - accuracy: 0.8532 - val_loss: 0.2737 - val_accuracy: 0.8908\n",
      "Epoch 2/20\n",
      "417/417 [==============================] - 6s 13ms/step - loss: 0.1482 - accuracy: 0.9511 - val_loss: 0.2814 - val_accuracy: 0.8848\n",
      "Epoch 3/20\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.0650 - accuracy: 0.9861 - val_loss: 0.3168 - val_accuracy: 0.8828\n",
      "Epoch 4/20\n",
      "417/417 [==============================] - 5s 13ms/step - loss: 0.0276 - accuracy: 0.9972 - val_loss: 0.3510 - val_accuracy: 0.8824\n",
      "209/209 [==============================] - 2s 6ms/step - loss: 0.2706 - accuracy: 0.8922\n",
      "Epoch 1/20\n",
      "625/625 [==============================] - 6s 8ms/step - loss: 0.3542 - accuracy: 0.8490 - val_loss: 0.2685 - val_accuracy: 0.8924\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 5s 7ms/step - loss: 0.1318 - accuracy: 0.9537 - val_loss: 0.3211 - val_accuracy: 0.8808\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 5s 8ms/step - loss: 0.0545 - accuracy: 0.9851 - val_loss: 0.4040 - val_accuracy: 0.8786\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 4s 7ms/step - loss: 0.0205 - accuracy: 0.9964 - val_loss: 0.4972 - val_accuracy: 0.8726\n"
     ]
    }
   ],
   "source": [
    "# Callbacks\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "\n",
    "\n",
    "print(\"BOW:\")\n",
    "bow_rnd_search_cv.fit(X_train_vectorized_bow, y_train, epochs=20, \n",
    "                        validation_data=(X_valid_vectorized_bow, y_valid), \n",
    "                        callbacks=[early_stopping_cb]);\n",
    "\n",
    "\n",
    "print(\"TF-IDF:\")\n",
    "tfidf_rnd_search_cv.fit(X_train_vectorized_tfidf, y_train, epochs=20, \n",
    "                        validation_data=(X_valid_vectorized_tfidf, y_valid), \n",
    "                        callbacks=[early_stopping_cb]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f733c4dd",
   "metadata": {},
   "source": [
    "## Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "760ae261",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Agustin\\AppData\\Local\\Temp\\ipykernel_10604\\1586490070.py:11: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  soup = BeautifulSoup(html_text, 'html.parser')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF - BoW Accuracy: 0.8476\n",
      "RF - TFIDF Accuracy: 0.84392\n",
      "782/782 [==============================] - 3s 2ms/step - loss: 0.2968 - accuracy: 0.8828\n",
      "FNN - BoW Accuracy: 0.8828399777412415\n",
      "782/782 [==============================] - 3s 3ms/step - loss: 0.3014 - accuracy: 0.8728\n",
      "FNN - TFIDF Accuracy: 0.8727999925613403\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test = test_set[\"review\"], test_set[\"sentiment\"]\n",
    "X_test_transformed = preprocessing_pipeline.transform(X_test)\n",
    "X_test_vectorized_bow = bow_vectorizer.transform(X_test_transformed)\n",
    "X_test_vectorized_tfidf = tfidf_vectorizer.transform(X_test_transformed)\n",
    "\n",
    "\n",
    "# Evaluate the best models on the test set\n",
    "rf_clf = RandomForestClassifier(n_estimators=100).fit(X_train_vectorized_bow, y_train)\n",
    "rf_bow_score = rf_clf.score(X_test_vectorized_bow, y_test)\n",
    "print(f\"RF - BoW Accuracy: {rf_bow_score}\")\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100).fit(X_train_vectorized_tfidf, y_train)\n",
    "rf_tfidf_score = rf_clf.score(X_test_vectorized_tfidf, y_test)\n",
    "print(f\"RF - TFIDF Accuracy: {rf_tfidf_score}\")\n",
    "\n",
    "fnn_bow_score = bow_rnd_search_cv.score(X_test_vectorized_bow, y_test)\n",
    "print(f\"FNN - BoW Accuracy: {fnn_bow_score}\")\n",
    "\n",
    "fnn_tfidf_score = tfidf_rnd_search_cv.score(X_test_vectorized_tfidf, y_test)\n",
    "print(f\"FNN - TFIDF Accuracy: {fnn_tfidf_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d06769",
   "metadata": {},
   "source": [
    "With these approaches we've achieved around 88% accuracy in this dataset. This performance might be improved using a Distributed Vector Representation for words (such as Word2vec, Doc2vec, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a66276e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
